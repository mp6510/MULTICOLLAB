#  MULTICOLLAB
MULTICOLLAB is a novel multimodal corpus for affective computing. This IRB-approved study was collected from 48 subjects, forming 24 builder and instructor pairs. Through a Zoom call, the instructor guided the builder through two tasks. This processed dataset consists of the instructor's facial features, eye tracking features, galvanic skin resposne, audio features, and manually verified transcipts surrounding the instances of annotation. All values are Z-Score normalized per modality. The annotations were provided by the instructor using a web-based online tool. See the full paper here.

## Dataset Description
### File Structure
We provide files X and Y tsv files while varying time window and time steps. Remember to to use the same X and y value that have the same time window and time steps in the filename.

### Video Sample
![Video](./sample.png)
[Watch it here](https://vimeo.com/839024815)

### Details
Each file has a corresponding README with details of each modality.

## Disclaimer and License
This dataset is licensed under the <a href="https://creativecommons.org/licenses/by-nc/4.0/" target="_blank">Creative Commons Attribution-NonCommercial 4.0 International License (CC-BY-NC-4.0)</a> and subject to [DISCLAIMER](DISCLAIMER.txt). 
 
## Citation and Contact
For any questions about this dataset, please contact Michael Peechatt at [mp6510@rit.edu](mailto:mp6510@rit.edu).)
## TODO
Insert BibTeX here
